{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTW Alignment to Virus Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manage all imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import multiprocessing as mp\n",
    "from numba import njit\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define globals for selecting input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_fn = \"../data/covid/reference.fasta\"\n",
    "kmer_model_fn = \"../data/dna_kmer_model.txt\"\n",
    "k = 6 # 6-mer model\n",
    "ref_read_fns = [\"../data/covid/fast5/SP1-mapped109.fast5\"]\n",
    "#ref_read_fns = glob(\"../data/covid/fast5/*.fast5\")\n",
    "max_ref_reads = 50\n",
    "other_read_fns = [\"../data/human/fast5/1000/reads.fast5\", \"../data/zymo/fast5/907/reads.fast5\"]\n",
    "#other_read_fns = glob(\"../data/human/chr20/*.fast5\")\n",
    "max_other_reads = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal-Based Reference Setup\n",
    "Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasta(fasta_fn):\n",
    "    ''' Get sequence from FASTA filename. '''\n",
    "    with open(fasta_fn, 'r') as fasta:\n",
    "        return ''.join(fasta.read().split('\\n')[1:])\n",
    "\n",
    "def rev_comp(bases):\n",
    "    ''' Get reverse complement of sequence. '''\n",
    "    return bases.replace('A','t').replace('T','a').replace('G','c').replace('C','g').upper()[::-1]\n",
    "\n",
    "def load_model(kmer_model_fn):\n",
    "    ''' Load k-mer model file into Python dict. '''\n",
    "    kmer_model = {}\n",
    "    with open(kmer_model_fn, 'r') as model_file:\n",
    "        for line in model_file:\n",
    "            kmer, current = line.split()\n",
    "            kmer_model[kmer] = float(current)\n",
    "    return kmer_model\n",
    "\n",
    "def discrete_normalize(seq, bits=8, minval=-4, maxval=4):\n",
    "    ''' Approximate normalization which converts signal to integer of desired precision. '''\n",
    "    mean = int(np.mean(seq))\n",
    "    mean_avg_dev = int(np.mean(np.abs(seq - mean)))\n",
    "    norm_seq = (seq - mean) / mean_avg_dev\n",
    "    \n",
    "    norm_seq[norm_seq < minval] = minval\n",
    "    norm_seq[norm_seq > maxval] = maxval\n",
    "    norm_seq = ( (norm_seq - minval) * (2**(bits)/(maxval-minval)) ).astype(int)\n",
    "    return norm_seq\n",
    "\n",
    "def ref_signal(fasta, kmer_model):\n",
    "    ''' Convert reference FASTA to expected reference signal (z-scores). '''\n",
    "    signal = np.zeros(len(fasta))\n",
    "    for kmer_start in range(len(fasta)-k):\n",
    "        signal[kmer_start] = kmer_model[fasta[kmer_start:kmer_start+k]]\n",
    "    return discrete_normalize(signal*100) # increase dist between floats before rounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create COVID reference using (z-score normalized) expected k-mer currents for forward/backward reference FASTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_fasta = get_fasta(ref_fn)\n",
    "kmer_model = load_model(kmer_model_fn)\n",
    "fwd_ref_sig = ref_signal(ref_fasta, kmer_model)\n",
    "rev_ref_sig = ref_signal(rev_comp(ref_fasta), kmer_model)\n",
    "ref_sig = np.concatenate((fwd_ref_sig, rev_ref_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define preprocessing functions for converting raw FAST5 data to normalized alignable signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stall_threshold = 200\n",
    "stall_events = 2\n",
    "stall_event_len = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stall_end(signal):\n",
    "    ''' Determine the end of the DNA stall region. '''\n",
    "    \n",
    "    # take average of a few samples to reduce variation\n",
    "    events = []\n",
    "    for event in range(0, len(signal), stall_event_len):\n",
    "        events.append(np.mean(signal[event:event+stall_event_len]))\n",
    "    \n",
    "    # find where we exceed threshold for a few consecutive events\n",
    "    above_threshold_count = 0\n",
    "    event_pos = 0\n",
    "    for event in events:\n",
    "        event_pos += 1\n",
    "        if event > stall_threshold:\n",
    "            above_threshold_count += 1\n",
    "        else:\n",
    "            above_threshold_count = 0\n",
    "        if above_threshold_count == stall_events:\n",
    "            break\n",
    "            \n",
    "    # find where we go back below threshold\n",
    "    below_threshold_count = 0\n",
    "    for event in events[event_pos:]:\n",
    "        event_pos += 1\n",
    "        if event < stall_threshold:\n",
    "            below_threshold_count += 1\n",
    "        else:\n",
    "            below_threshold_count = 0\n",
    "        if below_threshold_count == stall_events:\n",
    "            break\n",
    "            \n",
    "    return event_pos * stall_event_len\n",
    "\n",
    "\n",
    "def trim_signal(signal):\n",
    "    ''' Trims signal by detecting stall and adapter. '''\n",
    "    stall_end = get_stall_end(signal)\n",
    "    return signal[stall_end:]\n",
    "    \n",
    "\n",
    "def preprocess_reads(fast5_fn):\n",
    "    ''' Returns all preprocessed reads from specified FAST5 file. '''\n",
    "    fast5_file = h5py.File(fast5_fn, 'r')\n",
    "    reads = []\n",
    "    for read_name in fast5_file:\n",
    "        signal = np.array(fast5_file[read_name]['Raw']['Signal'][:], dtype=np.int16)\n",
    "        signal = discrete_normalize(signal)\n",
    "        trimmed_signal = trim_signal(signal)\n",
    "        reads.append(trimmed_signal)\n",
    "    return reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess reads into a list of NumPy arrays for each data source (ref/other), selecting a random subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_reads = []\n",
    "for fast5_fn in ref_read_fns:\n",
    "    ref_reads.extend(preprocess_reads(fast5_fn))\n",
    "random.shuffle(ref_reads)\n",
    "ref_reads = ref_reads[:max_ref_reads]\n",
    "    \n",
    "other_reads = []\n",
    "for fast5_fn in other_read_fns:\n",
    "    other_reads.extend(preprocess_reads(fast5_fn))\n",
    "random.shuffle(other_reads)\n",
    "other_reads = other_reads[:max_other_reads]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTW Alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define globals for use in DTW (reference signals and alignment lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = ref_sig\n",
    "aln_lens = np.array(range(1000,5001,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit()\n",
    "def sdtw(seq):\n",
    "    ''' Returns minimum alignment score for subsequence DTW. '''\n",
    "    \n",
    "    # initialize cost matrix\n",
    "    cost_mat = np.zeros((len(seq), len(ref)))\n",
    "    cost_mat[0, 0] = abs(seq[0]-ref[0])\n",
    "    for i in range(1, len(seq)):\n",
    "        cost_mat[i, 0] = cost_mat[i-1, 0] + abs(seq[i]-ref[0])\n",
    "\n",
    "    # compute entire cost matrix\n",
    "    for i in range(1, len(seq)):\n",
    "        for j in range(1, len(ref)):\n",
    "            cost_mat[i, j] = abs(seq[i]-ref[j]) + \\\n",
    "                min(cost_mat[i-1, j-1], cost_mat[i, j-1], cost_mat[i-1, j])\n",
    "    \n",
    "    # return cost of optimal alignment\n",
    "    cost_mins = np.zeros((len(aln_lens),))\n",
    "    for i in range(len(aln_lens)):\n",
    "        cost_mins[i] = min(cost_mat[aln_lens[i]-1,:])\n",
    "    return cost_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool() as pool:\n",
    "    ref_dists = pool.map(sdtw, ref_reads)\n",
    "    other_dists = pool.map(sdtw, other_reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [11000, 20000, 29000, 39000, 49000]\n",
    "for i, l in enumerate(aln_lens):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist([x[i] for x in ref_dists], bins=50, facecolor='r', alpha=0.5)\n",
    "    ax.hist([x[i] for x in other_dists], bins=50, facecolor='g', alpha=0.5)\n",
    "    ax.legend(['COVID', 'Human'])\n",
    "    ax.set_xlabel('DTW Alignment Cost')\n",
    "    ax.set_ylabel('Read Count')\n",
    "    ax.axvline(thresholds[i], color='k', linestyle='--')\n",
    "    ax.set_title('{} Signals'.format(l))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, l in enumerate(aln_lens):\n",
    "    pred = [x[i] < thresholds[i] for x in ref_dists] + \\\n",
    "            [x[i] < thresholds[i] for x in other_dists]\n",
    "    truth = [True]*len(ref_dists) + [False]*len(other_dists)\n",
    "    cm = metrics.confusion_matrix(pred, truth)\n",
    "    print(\"Alignment Length: {}\".format(l))\n",
    "    print(\"\\tCOVID Retention Rate: {}\".format(np.sum([x[i] < thresholds[i] for x in ref_dists])/len(ref_dists)))\n",
    "    print(\"\\tOther Discard Rate: {}\\n\".format(np.sum([x[i] > thresholds[i] for x in other_dists])/len(other_dists)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
