{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTW Alignment to Virus Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manage all imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import multiprocessing as mp\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define globals for selecting input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_fn = \"../data/covid/reference.fasta\"\n",
    "kmer_model_fn = \"../data/kmer_model.txt\"\n",
    "k = 6 # 6-mer model\n",
    "ref_read_fns = [\"../data/covid/fast5/1000/fwd/reads.fast5\", \"../data/covid/fast5/1000/rev/reads.fast5\"]\n",
    "max_ref_reads = 200\n",
    "other_read_fns = [\"../data/human/fast5/505/reads.fast5\"]\n",
    "max_other_reads = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal-Based Reference Setup\n",
    "Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasta(fasta_fn):\n",
    "    ''' Get sequence from FASTA filename. '''\n",
    "    with open(fasta_fn, 'r') as fasta:\n",
    "        return ''.join(fasta.read().split('\\n')[1:])\n",
    "\n",
    "def rev_comp(bases):\n",
    "    ''' Get reverse complement of sequence. '''\n",
    "    return bases.replace('A','t').replace('T','a').replace('G','c').replace('C','g').upper()[::-1]\n",
    "\n",
    "def load_model(kmer_model_fn):\n",
    "    ''' Load k-mer model file into Python dict. '''\n",
    "    kmer_model = {}\n",
    "    with open(kmer_model_fn, 'r') as model_file:\n",
    "        for line in model_file:\n",
    "            kmer, current = line.split()\n",
    "            kmer_model[kmer] = float(current)\n",
    "    return kmer_model\n",
    "\n",
    "def ref_signal(fasta, kmer_model):\n",
    "    ''' Convert reference FASTA to expected reference signal (z-scores). '''\n",
    "    signal = []\n",
    "    for kmer_start in range(len(fasta)-k):\n",
    "        signal.append(kmer_model[fasta[kmer_start:kmer_start+k]])\n",
    "    return stats.zscore(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create COVID reference using (z-score normalized) expected k-mer currents for forward/backward reference FASTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_fasta = get_fasta(ref_fn)\n",
    "kmer_model = load_model(kmer_model_fn)\n",
    "fwd_ref_sig = ref_signal(ref_fasta, kmer_model)\n",
    "rev_ref_sig = ref_signal(rev_comp(ref_fasta), kmer_model)\n",
    "ref_sig = np.concatenate((fwd_ref_sig, rev_ref_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define preprocessing functions for converting raw FAST5 data to normalized alignable signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_start():\n",
    "    ''' Heuristic for selecting read start. '''\n",
    "    # Note: this will later change to using stall/adapter/barcode information.\n",
    "    return 1000\n",
    "\n",
    "def read_stop(): \n",
    "    ''' Heuristic for selecting read stop. '''\n",
    "    # Note: this may later become variable.\n",
    "    return 4000\n",
    "\n",
    "def preprocess_reads(fast5_fn):\n",
    "    ''' Returns all preprocessed reads from specified FAST5 file. '''\n",
    "    fast5_file = h5py.File(fast5_fn, 'r')\n",
    "    reads = []\n",
    "    for read_name in fast5_file:\n",
    "        signal = np.array(fast5_file[read_name]['Raw']['Signal'][:], dtype=np.int16)\n",
    "        start, stop = read_start(), read_stop()\n",
    "        trimmed_signal = signal[start:stop]\n",
    "        if not len(trimmed_signal): continue # TODO: later check for != stop-start ?\n",
    "        reads.append(stats.zscore(trimmed_signal))\n",
    "    return reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess reads into a list of NumPy arrays for each data source (ref/other), selecting a random subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_reads = []\n",
    "for fast5_fn in ref_read_fns:\n",
    "    ref_reads.extend(preprocess_reads(fast5_fn))\n",
    "random.shuffle(ref_reads)\n",
    "ref_reads = ref_reads[:max_ref_reads]\n",
    "    \n",
    "other_reads = []\n",
    "for fast5_fn in other_read_fns:\n",
    "    other_reads.extend(preprocess_reads(fast5_fn))\n",
    "random.shuffle(other_reads)\n",
    "other_reads = other_reads[:max_other_reads]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTW Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdtw(seq):\n",
    "    ''' Returns minimum alignment score for subsequence DTW. '''\n",
    "    \n",
    "    # compute all pairwise signal differences\n",
    "    cost_mat = np.zeros((len(seq), len(ref_sig)))\n",
    "    delta_mat = np.zeros((len(seq), len(ref_sig)))\n",
    "    np.subtract.outer(seq, ref_sig, out=delta_mat[:len(seq),:len(ref_sig)])\n",
    "    np.square(delta_mat[:len(seq),:len(ref_sig)], out=delta_mat[:len(seq),:len(ref_sig)])  \n",
    "    \n",
    "    # initialize left side of cost_mat (top stays zero due to subsequence DTW)\n",
    "    cost_mat[0, 0] = delta_mat[0, 0]\n",
    "    for i in range(1, len(seq)):\n",
    "        cost_mat[i, 0] = cost_mat[i-1, 0]+delta_mat[i, 0]\n",
    "\n",
    "    # computer entire cost matrix\n",
    "    for i in range(1, len(seq)):\n",
    "        for j in range(1, len(ref_sig)):\n",
    "            cost_mat[i, j] = delta_mat[i, j] + \\\n",
    "                min(cost_mat[i-1, j-1], cost_mat[i, j-1], cost_mat[i-1, j])\n",
    "    \n",
    "    # return cost of optimal alignment\n",
    "    return np.sqrt(np.min(cost_mat[len(seq)-1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool() as pool:\n",
    "    ref_dists = pool.map(sdtw, ref_reads)\n",
    "    other_dists = pool.map(sdtw, other_reads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(ref_dists, bins=30, facecolor='r', alpha=0.5)\n",
    "ax.hist(other_dists, bins=30, facecolor='g', alpha=0.5)\n",
    "ax.legend(['COVID', 'human'])\n",
    "ax.set_xlabel('Alignment Cost')\n",
    "ax.set_ylabel('Read Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
